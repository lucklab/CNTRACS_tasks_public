{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting demo for the RLWM task\n",
    "This is a demo for how to fit the RLWM (Reinforcement Learning - Working Memory) model to data from the CNTRACTS RLWM task.\n",
    "\n",
    "There should be one sample data file ('demo_data.csv') included next to this script.\n",
    "The script demonstrates how the model can be fit to an individual participant data using maximum likelihood estimation (MLE).\n",
    "\n",
    "Author: Krishn Bera (krishn_bera@brown.edu)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the model\n",
    "\n",
    "The model used here is the a variant of the original RLWM model (Collins & Frank, 2012). The model captures learning behaviors through an interactive dual-process model of reinforcement learning (RL) and working memory (WM) processes. The RL system learns incrementally accumulating reward values of states and actions. The WM system is characterized as quick, one-shot learning system that is capacity-limited and prone to forgetting. Through this parallel recruitment of dual systems, the model is able to capture the WM-specific effects of load and delay on learning.\n",
    "\n",
    "--\n",
    "\n",
    "Collins, A.G.E. and Frank, M.J. (2012), How much of reinforcement learning is working memory, not reinforcement learning? A behavioral, computational, and neurogenetic analysis. European Journal of Neuroscience, 35: 1024-1035. https://doi.org/10.1111/j.1460-9568.2011.07980.x\n",
    "\n",
    "\n",
    "### Summary of the parameters estimated by the model\n",
    "\n",
    "- alpha -> learning rate of the RL system\n",
    "- phi -> WM decay rate\n",
    "- rho -> weight of the WM system\n",
    "- gamma -> perseveration parameter\n",
    "- epsilon -> noise/attention-lapse parameter\n",
    "- C -> working memory capacity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the RLWM model config as a dictionary\n",
    "# the dictionary contains the model name as the key, and a dictionary of parameter information as the value\n",
    "# the parameter information should include the parameter names and the parameter bounds (specified as two lists for the lower and upper bounds)\n",
    "\n",
    "model_config_rl = {\n",
    "    \"RLWM\": {\n",
    "        \"params\": [\"alpha\", \"phi\", \"rho\", \"gamma\", \"epsilon\"], # Note: C parameter is not included here\n",
    "        \"param_bounds\": [[0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0]],\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the fixed parameters and optimization settings\n",
    "\n",
    "model_rl = 'RLWM' # the model name (must be one of the keys in model_config_rl)\n",
    "num_actions = 3 # the number of actions in the RLWM task\n",
    "beta = 100 # the inverse temperature parameter in the softmax function\n",
    "\n",
    "C_list = [2, 3, 4, 5] # C is the working memory capacity. C_list is the list of C values to be iterated over during the optimization\n",
    "n_restarts = 20 # the number of random restarts for each C value during the optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate softmax of the Q values\n",
    "# beta is the inverse temperature parameter\n",
    "def softmax(q_val, beta):\n",
    "    q_val = np.array(q_val)*beta\n",
    "    q_val = np.exp(q_val)\n",
    "    q_val = q_val / np.sum(q_val)\n",
    "    return q_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to sample random starting points for random restarts during the optimization\n",
    "# the function returns a list of randomly sampled starting points for the parameters\n",
    "def sample_uniform_starting_pts(model_rl):\n",
    "\n",
    "    alpha_low = model_config_rl[model_rl]['param_bounds'][0][0]\n",
    "    alpha_high = model_config_rl[model_rl]['param_bounds'][1][0]\n",
    "\n",
    "    phi_low = model_config_rl[model_rl]['param_bounds'][0][1]\n",
    "    phi_high = model_config_rl[model_rl]['param_bounds'][1][1]\n",
    "\n",
    "    rho_low = model_config_rl[model_rl]['param_bounds'][0][2]\n",
    "    rho_high = model_config_rl[model_rl]['param_bounds'][1][2]\n",
    "\n",
    "    gamma_low = model_config_rl[model_rl]['param_bounds'][0][3]\n",
    "    gamma_high = model_config_rl[model_rl]['param_bounds'][1][3]\n",
    "\n",
    "    epsilon_low = model_config_rl[model_rl]['param_bounds'][0][4]\n",
    "    epsilon_high = model_config_rl[model_rl]['param_bounds'][1][4]\n",
    "\n",
    "    \n",
    "    alpha = random.uniform(alpha_low, alpha_high)\n",
    "    phi = random.uniform(phi_low, phi_high)\n",
    "    rho = random.uniform(rho_low, rho_high)\n",
    "    gamma = random.uniform(gamma_low, gamma_high)\n",
    "    epsilon = random.uniform(epsilon_low, epsilon_high)\n",
    "\n",
    "    starting_pts = [alpha, phi, rho, gamma, epsilon]\n",
    "    \n",
    "    return starting_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check for boundary violations of the parameters\n",
    "# the function returns True if there is a boundary violation, and False otherwise\n",
    "def check_boundary_violations(alpha, phi, rho, gamma, epsilon):\n",
    "    \n",
    "    if alpha < model_config_rl[model_rl]['param_bounds'][0][0] or alpha > model_config_rl[model_rl]['param_bounds'][1][0]:\n",
    "        return True\n",
    "    if phi < model_config_rl[model_rl]['param_bounds'][0][1] or phi > model_config_rl[model_rl]['param_bounds'][1][1]:\n",
    "        return True\n",
    "    if rho < model_config_rl[model_rl]['param_bounds'][0][2] or rho > model_config_rl[model_rl]['param_bounds'][1][2]:\n",
    "        return True\n",
    "    if gamma < model_config_rl[model_rl]['param_bounds'][0][3] or gamma > model_config_rl[model_rl]['param_bounds'][1][3]:\n",
    "        return True\n",
    "    if epsilon < model_config_rl[model_rl]['param_bounds'][0][4] or epsilon > model_config_rl[model_rl]['param_bounds'][1][4]:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the log likelihood of the RLWM model\n",
    "# this function is called by the scipy.optimize.minimize function during the optimization\n",
    "def RLWM_LL(params, subj_data, num_actions, C, beta):\n",
    "\n",
    "    # get the parameter values\n",
    "    alpha = params[0] \n",
    "    phi = params[1]  \n",
    "    rho = params[2] \n",
    "    gamma = params[3] \n",
    "    epsilon = params[4] \n",
    "\n",
    "    # check for boundary violations, return inf if there is a boundary violation\n",
    "    if check_boundary_violations(alpha, phi, rho, gamma, epsilon) == True:\n",
    "        return np.inf\n",
    "\n",
    "    # get the list of blocks in the data\n",
    "    block_list = np.unique(subj_data['block_id'])\n",
    "\n",
    "    # initialize the log likelihood\n",
    "    subj_ll = 0\n",
    "    subj_trl_idx = 0\n",
    "    \n",
    "    # iterate over blocks\n",
    "    for bl in block_list:\n",
    "\n",
    "        # extract the data for the current block\n",
    "        block_data = subj_data.loc[subj_data['block_id'] == bl]\n",
    "\n",
    "        # get the set size for the current block\n",
    "        set_size = len(np.unique(block_data['stim_id']))\n",
    "\n",
    "        # get the trials, rewards, and actions for the current block\n",
    "        trials = block_data['stim_id'].values\n",
    "        reward_list = block_data['feedback'].values\n",
    "        action_list = block_data['resp'].values\n",
    "\n",
    "        # initialize the Q values for the RL and WM systems\n",
    "        q_RL = np.ones((set_size, num_actions)) * 1/num_actions\n",
    "        q_WM = np.ones((set_size, num_actions)) * 1/num_actions\n",
    "\n",
    "        # initialize the weight term for the WM system\n",
    "        weight = rho * min(1, C/set_size)\n",
    "        \n",
    "        # initialize the policy\n",
    "        pol = np.zeros(num_actions)\n",
    "\n",
    "        # iterate over trials\n",
    "        for tr in np.arange(len(trials)):\n",
    "\n",
    "            # get the current state\n",
    "            state = int(trials[tr])\n",
    "\n",
    "            # compute the RL and WM policies using the Q values\n",
    "            pol_RL = softmax(q_RL[state, :], beta)\n",
    "            pol_WM = softmax(q_WM[state, :], beta)\n",
    "\n",
    "            # compute the mixed policy as the weighted sum of the RL and WM policies\n",
    "            pol = weight * pol_WM + (1-weight) * pol_RL\n",
    "\n",
    "            # computre the final policy as a mixture of the mixed policy and the noisy (uniform) policy\n",
    "            pol_final = (1 - epsilon) * pol + epsilon * np.tile([1/num_actions], num_actions)\n",
    "\n",
    "            # get the action\n",
    "            action = int(action_list[tr])\n",
    "\n",
    "            # get the reward\n",
    "            # Note: reward is always 1 for the RLWM model if the participant responds correctly and 0 otherwise\n",
    "            if reward_list[tr] == 1 or reward_list[tr] == 2:\n",
    "                reward = 1\n",
    "            elif reward_list[tr] == 0:\n",
    "                reward = 0\n",
    "\n",
    "            # compute the log likelihood for the trial and add it to subject's log likelihood\n",
    "            subj_ll += np.log(pol_final[action])\n",
    "            \n",
    "            # update the Q values for the RL and WM systems\n",
    "            # if the RPE is negative, the Q values are updated using the perseveration parameter gamma\n",
    "            if (reward - q_RL[state, action]) >= 0:\n",
    "                q_RL[state, action] = q_RL[state, action] + alpha * (reward - q_RL[state, action])\n",
    "                q_WM[state, action] = q_WM[state, action] + 1 * (reward - q_WM[state, action])\n",
    "            else:\n",
    "                q_RL[state, action] = q_RL[state, action] + gamma * alpha * (reward - q_RL[state, action])\n",
    "                q_WM[state, action] = q_WM[state, action] + gamma * 1 * (reward - q_WM[state, action])\n",
    "\n",
    "            # WM decay on each trial, update the Q values for the WM system\n",
    "            q_WM = q_WM + phi * ((1/num_actions)-q_WM)\n",
    "\n",
    "            subj_trl_idx += 1\n",
    "    \n",
    "    # return the negative log likelihood\n",
    "    return -subj_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv file as a dataframe\n",
    "data = pd.read_csv('demo_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_idx</th>\n",
       "      <th>ns</th>\n",
       "      <th>block_id</th>\n",
       "      <th>stim_id</th>\n",
       "      <th>rt</th>\n",
       "      <th>resp</th>\n",
       "      <th>corr_resp</th>\n",
       "      <th>acc</th>\n",
       "      <th>feedback</th>\n",
       "      <th>FBProb</th>\n",
       "      <th>stim_ctr</th>\n",
       "      <th>delay</th>\n",
       "      <th>early_late</th>\n",
       "      <th>pcor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>268</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800853</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.539283</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>268</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.816042</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>268</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.953407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>268</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.587742</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>268</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.574108</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>268</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>268</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.564499</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>268</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.504278</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subj_idx  ns  block_id  stim_id        rt  resp  corr_resp  acc  \\\n",
       "0         268   4         0        0  0.523952     0          0    1   \n",
       "1         268   4         0        0  0.800853     0          0    1   \n",
       "2         268   4         0        1  0.539283     1          2    0   \n",
       "3         268   4         0        1  0.816042     2          2    1   \n",
       "4         268   4         0        2  0.953407     0          0    1   \n",
       "..        ...  ..       ...      ...       ...   ...        ...  ...   \n",
       "354       268   5         9        1  0.587742     0          0    1   \n",
       "355       268   5         9        2  0.574108     2          2    1   \n",
       "356       268   5         9        0  0.561117     0          0    1   \n",
       "357       268   5         9        4  0.564499     2          2    1   \n",
       "358       268   5         9        3  0.504278     2          2    1   \n",
       "\n",
       "     feedback  FBProb  stim_ctr  delay  early_late  pcor  \n",
       "0           1     0.2       1.0      0           0     0  \n",
       "1           1     0.2       2.0      1          -1     1  \n",
       "2           0     0.8       1.0      0           0     0  \n",
       "3           2     0.8       2.0      0           0     0  \n",
       "4           1     0.5       1.0      0           0     0  \n",
       "..        ...     ...       ...    ...         ...   ...  \n",
       "354         2     0.8      10.0      5           1     9  \n",
       "355         1     0.5      10.0      5           1     7  \n",
       "356         1     0.2      10.0      8           1     9  \n",
       "357         1     0.2      10.0      5           1     7  \n",
       "358         2     0.5      10.0      5           1     7  \n",
       "\n",
       "[359 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the best negative log likelihood to infinity\n",
    "best_negLL = np.inf\n",
    "\n",
    "# iterate over the C values to find the best fit C value\n",
    "for C in C_list:\n",
    "\n",
    "    # perform multiple restarts of the optimization to avoid local minima\n",
    "    for n_r in range(n_restarts):\n",
    "\n",
    "        # specify arguments for the RLWM_LL function; these are fixed arguments passed to the RLWM_LL function\n",
    "        args = (data, num_actions, C, beta)\n",
    "        \n",
    "        # sample starting points for the parameters\n",
    "        x0 = sample_uniform_starting_pts(model_rl)\n",
    "\n",
    "        # optimize the parameters using the Nelder-Mead MLE method\n",
    "        res = minimize(RLWM_LL, x0, args=args, method='Nelder-Mead')\n",
    "\n",
    "        # get the negative log likelihood with the best fit parameters\n",
    "        m_negLL = RLWM_LL(res.x, data, num_actions, C, beta)\n",
    "\n",
    "        # if the negative log likelihood is lower than the current best, update the best parameters\n",
    "        if m_negLL < best_negLL:\n",
    "            best_x = res.x\n",
    "            best_x = np.append(best_x, C)\n",
    "            best_negLL = m_negLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best fit parameters: \n",
      "\n",
      "alpha  -  0.02315\n",
      "phi  -  0.23377\n",
      "rho  -  1.0\n",
      "gamma  -  0.42864\n",
      "epsilon  -  0.00617\n",
      "C -  3.0\n"
     ]
    }
   ],
   "source": [
    "# print the best fit parameters\n",
    "print('Best fit parameters: \\n')\n",
    "for i in range(len(best_x)-1):\n",
    "    print(model_config_rl[model_rl]['params'][i], \" - \", np.round(best_x[i], 5))\n",
    "print(\"C - \", best_x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hddm_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "beec005ddc6da8df6a59e4f4377e8f11991c267ba0430fb2b77e7427455f0fce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
